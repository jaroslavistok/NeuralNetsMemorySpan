@ARTICLE{Elman90findingstructure,
    author = {Jeffrey L. Elman},
    title = {Finding structure in time},
    journal = {COGNITIVE SCIENCE},
    year = {1990},
    volume = {14},
    number = {2},
    pages = {179--211}
}

@article{Ritter:1989:SSM:2730681.2730708,
 author = {Ritter, H. and Kohonen, T.},
 title = {Self-organizing Semantic Maps},
 journal = {Biol. Cybern.},
 issue_date = {August    1989},
 volume = {61},
 number = {4},
 month = aug,
 year = {1989},
 issn = {0340-1200},
 pages = {241--254},
 numpages = {14},
 url = {http://dx.doi.org/10.1007/BF00203171},
 doi = {10.1007/BF00203171},
 acmid = {2730708},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
} 

@article{Voegtlin:2002:RSM:776097.776102,
 author = {Voegtlin, Thomas},
 title = {Recursive Self-organizing Maps},
 journal = {Neural Netw.},
 issue_date = {October 2002},
 volume = {15},
 number = {8-9},
 month = oct,
 year = {2002},
 issn = {0893-6080},
 pages = {979--991},
 numpages = {13},
 url = {http://dx.doi.org/10.1016/S0893-6080(02)00072-2},
 doi = {10.1016/S0893-6080(02)00072-2},
 acmid = {776102},
 publisher = {Elsevier Science Ltd.},
 address = {Oxford, UK, UK},
 keywords = {kohonen map, recurrent networks, recursive self-organizing maps, recursiveness, time},
} 

@article{DBLP:journals/ijon/StrickertH05,
  author    = {Marc Strickert and
               Barbara Hammer},
  title     = {Merge {SOM} for temporal data},
  journal   = {Neurocomputing},
  volume    = {64},
  pages     = {39--71},
  year      = {2005}
}

@article{Kohonen:2013:ESM:2405841.2405960,
 author = {Kohonen, Teuvo},
 title = {Essentials of the Self-organizing Map},
 journal = {Neural Netw.},
 issue_date = {January, 2013},
 volume = {37},
 month = jan,
 year = {2013},
 issn = {0893-6080},
 pages = {52--65},
 numpages = {14},
 url = {http://dx.doi.org/10.1016/j.neunet.2012.09.018},
 doi = {10.1016/j.neunet.2012.09.018},
 acmid = {2405960},
 publisher = {Elsevier Science Ltd.},
 address = {Oxford, UK, UK},
 keywords = {Brain map, Data analysis, SOM, Self-organizing map, Similarity, Vector quantization},
} 

@article{guo2013backpropagation,
  added-at = {2018-11-26T22:47:12.000+0100},
  author = {Guo, Jiang},
  biburl = {https://www.bibsonomy.org/bibtex/2b3567a1db4101fa0f0fe32f7276501a9/habereder},
  interhash = {beeabee01f1fd5d9d81839382726a778},
  intrahash = {b3567a1db4101fa0f0fe32f7276501a9},
  journal = {Unpubl. ms., Harbin Institute of Technology},
  keywords = {imported thema:seqtoseq},
  timestamp = {2018-11-26T22:48:39.000+0100},
  title = {Backpropagation through time},
  year = 2013
}

@article{rsm,
author="Ti{\v{n}}o, Peter
and Farka{\v{s}}, Igor
and van Mourik, Jort",
editor="Gallagher, Marcus
and Hogan, James P.
and Maire, Frederic",
title="Recursive Self-organizing Map as a Contractive Iterative Function System",
booktitle="Intelligent Data Engineering and Automated Learning - IDEAL 2005",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="327--334",
abstract="Recently, there has been a considerable research activity in extending topographic maps of vectorial data to more general data structures, such as sequences or trees. However, the representational capabilities and internal representations of the models are not well understood. We rigorously analyze a generalization of the Self-Organizing Map (SOM) for processing sequential data, Recursive SOM (RecSOM [1]), as a non-autonomous dynamical system consisting of a set of fixed input maps. We show that contractive fixed input maps are likely to produce Markovian organizations of receptive fields on the RecSOM map. We derive bounds on parameter $\beta$ (weighting the importance of importing past information when processing sequences) under which contractiveness of the fixed input maps is guaranteed.",
isbn="978-3-540-31693-0"
}

@ARTICLE{markovnian_bias, 
author={P. {Tino} and M. {Cernansky} and L. {Benuskova}}, 
journal={IEEE Transactions on Neural Networks}, 
title={Markovian architectural bias of recurrent neural networks}, 
year={2004}, 
volume={15}, 
number={1}, 
pages={6-15}, 
keywords={recurrent neural nets;Markov processes;context-free languages;learning (artificial intelligence);neural net architecture;pattern clustering;Markovian architectural bias;recurrent neural networks;clustering;recurrent layer;activation clusters;continuous state space network dynamics;predictive models;neural prediction machines;sigmoid activation functions;Markov prediction contexts;variable memory length Markov models;chaotic symbolic sequence;context-free language;deep recursive structure;complex symbolic sequences;information latching problem;iterative function systems;Recurrent neural networks;Data mining;Predictive models;State-space methods;Chaos;History;Neural networks;Information processing;Iterative algorithms;Automata;Markov Chains;Neural Networks (Computer)}, 
doi={10.1109/TNN.2003.820839}, 
ISSN={1045-9227}, 
month={Jan},}

@Article{Servan-Schreiber1991,
author="Servan-Schreiber, David
and Cleeremans, Axel
and Mcclelland, James L.",
title="Graded state machines: The representation of temporal contingencies in simple recurrent networks",
journal="Machine Learning",
year="1991",
month="Sep",
day="01",
volume="7",
number="2",
pages="161--193",
issn="1573-0565",
doi="10.1007/BF00114843",
url="https://doi.org/10.1007/BF00114843"
}



