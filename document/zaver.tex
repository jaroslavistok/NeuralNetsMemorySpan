\chapter*{Záver}
V našej práci sme porovnali pamäťovú hĺbku niekoľkých typov neurónových sietí.
Hlavným cieľom bolo zistiť, či sa dajú rekurentné samoorganizujúce sa mapy použiť na vizualizáciu
sekvenčných vstupov, teda s akým dlhým kontextom do minulosti dokážu pracovať. Chceli sme tiež navrhnúť 
spôsob ako merať a hlavne porovnať pamäťovú hĺbku Elmanovej siete so rekurentnými SOM-kami, prípadne 
nájsť súvislosti medzi týmito dvomi sieťami.

V našich experimentoch sme porovnávali pamäťovú hĺbku dvoch základných typov rekurentných 
SOM --- RecSOM a MSOM. Okrem toho sme si vytvorili z oboch modelov modifikované verzie --- Activity RecSOM a Decaying MSOM.
Activity RecSOM umožňuje experimentovať s hodnotami aktivít neurónov, ktoré tvoria kontext siete. Upravili sme v nej
vzorec na výpočet aktivity, tak aby obsahoval meniteľný parameter, ktorý môžeme nastavovať na rôzne hodnoty.
To nám umožnilo preskúmať ďaľšie vlastnosti RecSOM a vplyv zloženia kontextu na hĺbku pamäte RecSOM.
Pri modifikácii MSOM sme sa rozhodli, že použijeme úplne odlišný kontext ako používa MSOM. Pri klasickej MSOM
je kontext tvorený lineárnou kombináciou vlastností víťazného neurónu z predchádzajúceho kroku, v našej modifikovanej 
verzii je kontext tvorený iba kombináciou minulých vstupov a teda nie je závislý od minulých stavov samotnej siete.

Našimi experimentami sme zistili rôzne zaujímavé súvislosti medzi hodnotami pamäťovej hĺbky a kvantizačnými chybami.
Pri Activity RecSOM sme zistili, že zmenou priebehu funkcie na výpočet aktivácie neurónu vieme znížiť 
veľkosť kvantizačnej chyby, čiže zlepšiť trénovanie siete.
Decay MSOM nám ukázala, že s použitím kontextu nezávislého od stavov siete vieme dosiahnuť \textbf{najvyššie hodnoty pamäťových hĺbok}, pričom nezávisí od
natrénovanosti kontextových váh.
Z vlastností kontextov jednotlivých typov sietí vyplýva, že pre nízkodimenzionálne vstupy nemá zmysel používať RecSOM alebo Activity RecSOM, pretože 
MSOM a Decay MSOM sú výpočtovo ďaleko efektívnejšie (vďaka nízkej dimenzii kontextu) a tiež dosahujú vyššie hodnoty pamäťovej hĺbky pri použití optimálnych parametrov.


\section{Limity a nedostatky riešenia}
V experimente s Elmanovou sieťou sa nám podarilo nájsť spôsob ako vizualizovať súvislosti medzi 
aktiváciami neurónov na skrytej vrstve a posuvnými oknami na trénovacej množine, avšak 
nepodarilo sa nám nájsť spôsob ako zmerať a porovnať pamäťovú hĺbku Elmanovej siete s rekurentnými SOM.
Otázne je, či tento typ siete má kvantifikovateľnú pamäťovú hĺbku a či ju vieme odmerať a kvantifikovať.

\section{Možnosti ďaľšej práce}
\begin{itemize}
    \item Medzi ďaľšie možnosti patrí vyskúšanie ďaľších modifikácií rekurentných SOM. 
    Napríklad pri Acitivty RecSOM by sme mohli použiť euklidovskú vzdialenosť neurónu od víťazného neurónu a pozrieť sa na to aký vplyv by to malo 
    na pamäťovú hĺbku siete s rôznymi hodnotami parametra $\beta$.
    \item V našich experimentoch sme skúšali kombinácie parametrov $\alpha$ a $\beta$. Túto množinu parametrov by bolo vhodné rozšíriť o ďalšie parametre, napríklad
    lepšie preskúmať vplyv veľkosti okolia, či rýchlosti učenia siete.
    \item Keďže niektoré výsledky boli skreslené, vhodné by bolo lepšie kvantifikovať pamäťovú hĺbku v prípade, že neuróny rekurentných SOM majú vo svojom
    receptívnom poli uloženú iba jednu sekvenciu. 
    Tiež by bolo vhodné analyzovať lepšie súvislosti medzi kvantizačnou chybou a hodnotami pamäťovej hĺbky.
    \item V našej práci sa nevenujeme príliš matematickej analýze pri jednotlivých experimentoch.
    Preto by bolo vhodné spraviť podrobnú matematickú analýzu jednotlivých experimentov.
    \item Keďže sme nedokázali nájsť spôsob, ako zmerať pamäťovú hĺbku Elamnovej siete, určite by bolo 
    v budúcnosti vhodné navrhnúť a vyskúšať viac alternatívnych spôsobov ako zmerať pamäťovú hĺbku Elmanovej siete. 
    Napríklad podrobnejšiou analýzou dendrogramov, či hľadaním ďaľších súvislostí v stavovom priestore siete.
    \item Vyskúšať a overiť výsledky nášich experimentov v nejakom konkrétnom modeli strojového učenia, ktorý dokáže 
    využiť rekurentné neurónové siete na generovanie textu, či reprezentáciu sekvenčných dát.
    \item Keďže naše implementácie nepatria medzi tie optimálne, medzi ďaľšie možnosti práce
    určite patrí aj optimalizácia rýchlosti implementácii rekurentných SOM. Napríklad upraviť algoritmy tak, aby využívali
    pararelizmus a teda aby sme mohli vyskúšať väčšie množstvo kombinácii rôznych parametrov.
\end{itemize}





